{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.fft import rfft\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy.linalg import norm, eig\n",
    "from scipy.signal import cwt, morlet, ricker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients_data = {p: {} for p in ['p1', 'p2', 'p3', 'p4']}\n",
    "\n",
    "data = data[data.Stimulus_ID != -1]\n",
    "\n",
    "for p in ['p1', 'p2', 'p3', 'p4']:\n",
    "    pat = data[data.PatientID == p]\n",
    "    pat = pat.select(lambda x: pat[x].iloc[0]!=-999999, axis=1)\n",
    "    \n",
    "    ans = pat[pat.Stimulus_Type != 101].groupby(['Stimulus_ID']).head(1).Stimulus_Type.apply(lambda x: 0 if x<51 else 1) \n",
    "    patients_data[p]['ans'] = list(ans)\n",
    "    \n",
    "    num_epoch = len(patients_data[p]['ans'])\n",
    "    channels = pat.shape[1] - 3\n",
    "    time = 800\n",
    "    pat_data = patients_data[p]['data'] = np.zeros((num_epoch, 1, channels, time)) \n",
    "    \n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        epoch_data = pat[pat.Stimulus_ID == epoch].iloc[:time, 1:-2]\n",
    "        pat_data[epoch-1, 0] = ((epoch_data - np.mean(epoch_data, axis=0))/np.std(epoch_data, axis=0)).T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, Convolution1D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop, Adagrad\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.regularizers import l2\n",
    "import numpy as np, keras, pickle\n",
    "\n",
    "class SaveBestModel(keras.callbacks.Callback):\n",
    "    def __init__(self, patient):\n",
    "        self.max_acc = 0\n",
    "        self.min_loss = 100\n",
    "        self.patient = patient\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_acc = logs.get('val_acc')\n",
    "        val_loss = logs.get('val_loss') \n",
    "        if val_acc > self.max_acc and val_loss < self.min_loss:\n",
    "            np.savez(self.patient, data=self.model.get_weights())\n",
    "            self.max_acc = val_acc\n",
    "            self.min_loss = val_loss\n",
    "            \n",
    "\n",
    "PERCENTAGE = 0.8\n",
    "\n",
    "for p in ['p1', 'p2', 'p3', 'p4']:\n",
    "    X, y = patients_data[p]['data'], np.array(patients_data[p]['ans'])\n",
    "    TRAIN_TEST_SPLIT = int(X.shape[0] * PERCENTAGE)\n",
    "    X_train, X_test = X[:TRAIN_TEST_SPLIT], X[TRAIN_TEST_SPLIT:]\n",
    "    Y_train, Y_test = y[:TRAIN_TEST_SPLIT], y[TRAIN_TEST_SPLIT:]\n",
    "\n",
    "    model = Sequential()\n",
    "    if p!='p4':\n",
    "        model.add(GaussianNoise(1, input_shape=X.shape[1:]))\n",
    "    model.add(Convolution2D(10, X.shape[2], 1, input_shape=X.shape[1:], activation='relu', init='normal'))\n",
    "    model.add(Convolution2D(5, 1, 16, subsample=(1, 8), activation='relu', init='normal'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(30, activation='sigmoid', init='normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', init='normal'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=Adagrad(), metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint = SaveBestModel(p)\n",
    "    bsize = 8 if p=='p4' else 4\n",
    "    model.fit(X_train, Y_train, batch_size=bsize, nb_epoch=30, validation_data=(X_test, Y_test),\n",
    "             callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python2.7 submission.py create sub      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
